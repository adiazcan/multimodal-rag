{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "# Import the Pinecone library\n",
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "\n",
    "# Initialize a Pinecone client with your API key\n",
    "pc = Pinecone(api_key)\n",
    "\n",
    "# Create a serverless index\n",
    "index_name = \"my-test-index\"\n",
    "\n",
    "# if not pc.has_index(index_name):\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=3072,\n",
    "    metric=\"cosine\",\n",
    "    spec=ServerlessSpec(\n",
    "        cloud='aws',\n",
    "        region='us-east-1'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Wait for the index to be ready\n",
    "while not pc.describe_index(index_name).status['ready']:\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing PDFs and Extracting Visual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document processing started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Pages: 100%|██████████| 49/49 [14:58<00:00, 18.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document processing completed.\n",
      "DataFrame created with page data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "from pdf2image import convert_from_bytes\n",
    "from io import BytesIO\n",
    "from openai import AzureOpenAI\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Link to the document we will use as the example \n",
    "document_to_parse = \"https://documents1.worldbank.org/curated/en/099101824180532047/pdf/BOSIB13bdde89d07f1b3711dd8e86adb477.pdf\"\n",
    "\n",
    "# OpenAI client \n",
    "# oai_client = OpenAI()\n",
    "oai_client = AzureOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=\"2024-08-01-preview\",\n",
    ")\n",
    "\n",
    "# Chunk the PDF document into single page chunks \n",
    "def chunk_document(document_url):\n",
    "    # Download the PDF document\n",
    "    response = requests.get(document_url)\n",
    "    pdf_data = response.content\n",
    "\n",
    "    # Read the PDF data using PyPDF2\n",
    "    pdf_reader = PdfReader(BytesIO(pdf_data))\n",
    "    page_chunks = []\n",
    "\n",
    "    for page_number, page in enumerate(pdf_reader.pages, start=1):\n",
    "        pdf_writer = PdfWriter()\n",
    "        pdf_writer.add_page(page)\n",
    "        pdf_bytes_io = BytesIO()\n",
    "        pdf_writer.write(pdf_bytes_io)\n",
    "        pdf_bytes_io.seek(0)\n",
    "        pdf_bytes = pdf_bytes_io.read()\n",
    "        page_chunk = {\n",
    "            'pageNumber': page_number,\n",
    "            'pdfBytes': pdf_bytes\n",
    "        }\n",
    "        page_chunks.append(page_chunk)\n",
    "\n",
    "    return page_chunks\n",
    "\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(local_image_path):\n",
    "    with open(local_image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "\n",
    "# Function to convert page to image     \n",
    "def convert_page_to_image(pdf_bytes, page_number):\n",
    "    # Convert the PDF page to an image\n",
    "    images = convert_from_bytes(pdf_bytes)\n",
    "    image = images[0]  # There should be only one page\n",
    "\n",
    "    # Define the directory to save images (relative to your script)\n",
    "    images_dir = 'images'  # Use relative path here\n",
    "\n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(images_dir, exist_ok=True)\n",
    "\n",
    "    # Save the image to the images directory\n",
    "    image_file_name = f\"page_{page_number}.png\"\n",
    "    image_file_path = os.path.join(images_dir, image_file_name)\n",
    "    image.save(image_file_path, 'PNG')\n",
    "\n",
    "    # Return the relative image path\n",
    "    return image_file_path\n",
    "\n",
    "\n",
    "# Pass the image to the LLM for interpretation  \n",
    "def get_vision_response(prompt, image_path):\n",
    "    # Getting the base64 string\n",
    "    base64_image = encode_image(image_path)\n",
    "\n",
    "    response = oai_client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": prompt},\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                        },\n",
    "                    },\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\n",
    "# Process document function that brings it all together \n",
    "def process_document(document_url):\n",
    "    try:\n",
    "        # Update document status to 'Processing'\n",
    "        print(\"Document processing started\")\n",
    "\n",
    "        # Get per-page chunks\n",
    "        page_chunks = chunk_document(document_url)\n",
    "        total_pages = len(page_chunks)\n",
    "\n",
    "        # Prepare a list to collect page data\n",
    "        page_data_list = []\n",
    "\n",
    "        # Add progress bar here\n",
    "        for page_chunk in tqdm(page_chunks, total=total_pages, desc='Processing Pages'):\n",
    "            page_number = page_chunk['pageNumber']\n",
    "            pdf_bytes = page_chunk['pdfBytes']\n",
    "\n",
    "            # Convert page to image\n",
    "            image_path = convert_page_to_image(pdf_bytes, page_number)\n",
    "\n",
    "            # Prepare question for vision API\n",
    "            system_prompt = (\n",
    "                \"The user will provide you an image of a document file. Perform the following actions: \"\n",
    "                \"1. Transcribe the text on the page. **TRANSCRIPTION OF THE TEXT:**\"\n",
    "                \"2. If there is a chart, describe the image and include the text **DESCRIPTION OF THE IMAGE OR CHART**\"\n",
    "                \"3. If there is a table, transcribe the table and include the text **TRANSCRIPTION OF THE TABLE**\"\n",
    "            )\n",
    "\n",
    "            # Get vision API response\n",
    "            vision_response = get_vision_response(system_prompt, image_path)\n",
    "\n",
    "            # Extract text from vision response\n",
    "            text = vision_response.choices[0].message.content\n",
    "\n",
    "            # Collect page data\n",
    "            page_data = {\n",
    "                'PageNumber': page_number,\n",
    "                'ImagePath': image_path,\n",
    "                'PageText': text\n",
    "            }\n",
    "            page_data_list.append(page_data)\n",
    "\n",
    "        # Create DataFrame from page data\n",
    "        pdf_df = pd.DataFrame(page_data_list)\n",
    "        print(\"Document processing completed.\")\n",
    "        print(\"DataFrame created with page data.\")\n",
    "\n",
    "        # Return the DataFrame\n",
    "        return pdf_df\n",
    "\n",
    "    except Exception as err:\n",
    "        print(f\"Error processing document: {err}\")\n",
    "        # Update document status to 'Error'\n",
    "\n",
    "\n",
    "df = process_document(document_to_parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PageNumber</th>\n",
       "      <th>ImagePath</th>\n",
       "      <th>PageText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>images/page_1.png</td>\n",
       "      <td>**TRANSCRIPTION OF THE TEXT:**\\n\\nA BETTER BANK FOR A BETTER WORLD\\n\\nANNUAL REPORT 2024\\n\\nWORLD BANK GROUP\\nIBRD - IDA\\n\\nPublic Disclosure Authorized\\nPublic Disclosure Authorized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>images/page_2.png</td>\n",
       "      <td>**TRANSCRIPTION OF THE TEXT:**\\n\\nCONTENTS\\nMessage from the President \\t6\\nMessage from the Executive Directors \\t8\\nBecoming a Better Bank \\t10\\nFiscal 2024 Financial Summary \\t12\\nResults by Region \\t14\\nResults by Theme \\t44\\nHow We Work \\t68\\n\\nKEY TABLES\\nIBRD Key Financial Indicators, Fiscal 2020–24 \\t84\\nIDA Key Financial Indicators, Fiscal 2020–24 \\t88\\n\\nThis annual report, which covers the period from July 1, 2023, to June 30, 2024, has been prepared by the Executive Directors of both the International Bank for Reconstruction and Development (IBRD) and the International Development Association (IDA)—collectively known as the World Bank—in accordance with the respective bylaws of the two institutions. Ajay Banga, President of the World Bank Group and Chairman of the Board of Executive Directors, has submitted this report, together with the accompanying administrative budgets and audited financial statements, to the Board of Governors.\\n\\nAnnual reports for the other World Bank Group institutions—the International Finance Corporation (IFC), the Multilateral Investment Guarantee Agency (MIGA), and the International Centre for Settlement of Investment Disputes (ICSID)—are published separately. Key highlights from each institution's annual report are available in the World Bank Group Annual Report Summary.\\n\\nThroughout the report, the term World Bank and the abbreviated Bank refer only to IBRD and IDA; the term World Bank Group and the abbreviated Bank Group refer to the five institutions. All dollar amounts used in this report are current U.S. dollars unless otherwise specified. Funds allocated to multiregional projects are accounted for by recipient country where possible in tables and text when referring to regional breakdowns. For sector and theme breakdowns, funds are accounted for by operation. Fiscal year commitments and disbursements data are in accordance with the audited figures reported in the IBRD and IDA Financial Statements and Management's Discussion and Analysis documents for fiscal 2024. As a result of rounding, numbers in tables may not add to totals, and percentages in figures may not add to 100.\\n\\n---\\n\\n**DESCRIPTION OF THE IMAGE OR CHART**\\n\\nThe image shows a close-up of a person's hand holding a bunch of rice stalks. The hand appears weathered, suggesting the person might be engaged in agricultural work. The background is blurred but appears to show a field or a similar outdoor setting with some greenery. The World Bank Annual Report 2024 is printed in the bottom left corner of the image.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>images/page_3.png</td>\n",
       "      <td>**TRANSCRIPTION OF THE TEXT:**\\n\\n**ABOUT US**\\n\\nThe World Bank Group is one of the world’s largest sources of funding and knowledge for developing countries. Our five institutions share a commitment to reducing poverty, increasing shared prosperity, and promoting sustainable development.\\n\\n**OUR VISION**\\nOur vision is to create a world free of poverty on a livable planet.\\n\\n**OUR MISSION**\\nOur mission is to end extreme poverty and boost shared prosperity on a livable planet. This is threatened by multiple, intertwined crises. Time is of the essence. We are building a better Bank to drive impactful development that is:\\n- Inclusive of everyone, including women and young people;\\n- Resilient to shocks, including against climate and biodiversity crises, pandemics and fragility;\\n- Sustainable, through growth and job creation, human development, fiscal and debt management, food security and access to clean air, water, and affordable energy.\\n\\nTo achieve this, we will work with all clients as one World Bank Group, in close partnership with other multilateral institutions, the private sector, and civil society.\\n\\n**OUR CORE VALUES**\\nOur work is guided by our core values: impact, integrity, respect, teamwork, and innovation. These inform everything we do, everywhere we work.\\n\\n**DESCRIPTION OF THE IMAGE OR CHART**\\nThe image shows two people wearing white clothes, embracing each other. Behind them, there is an out-of-focus background that includes some greenery.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>images/page_4.png</td>\n",
       "      <td>**TRANSCRIPTION OF THE TEXT:**\\n\\nDRIVING ACTION, MEASURING RESULTS\\n\\nThe World Bank Group contributes to impactful, meaningful development results around the world. In the first half of fiscal 2024*, we:\\n\\nHelped feed 156 million people\\n\\nImproved schooling for 280 million students\\n\\nReached 287 million people living in poverty with effective social protection support†\\n\\nProvided healthy water, sanitation, and/or hygiene to 59 million people\\n\\nEnabled access to sustainable transportation for 77 million people\\n\\nProvided 17 gigawatts of renewable energy capacity\\n\\nCommitted to devote 45 percent of annual financing to climate action by 2025, deployed equally between mitigation and adaptation\\n\\n*The development of the new Scorecard is ongoing at the time of printing; therefore, this report can only account for results up to December 31, 2023. \\n†As of the 2024 IMF-World Bank Group Annual Meetings, the final fiscal 2024 Scorecard data will be available at: https://scorecard.worldbankgroup.org\\n\\nIn fiscal 2024, the Bank Group announced the development of a new Scorecard that will track results across 22 indicators—a fraction of the previous 150—to provide a streamlined, clear picture of progress on all aspects of the Bank Group’s mission, from improving access to healthcare to making food systems sustainable to boosting private investment.\\n\\nFor the first time, the work of all Bank Group financing institutions will be tracked through the same set of indicators. The new Scorecard will track the Bank Group’s overarching vision of ending poverty on a livable planet.\\n\\n**DESCRIPTION OF THE IMAGE OR CHART:**\\nThere are images associated with each of the bulleted points. These images depict the following:\\n\\n1. Food plates, representing helping feed 156 million people.\\n2. Children in uniform, representing improved schooling for 280 million students.\\n3. An individual with a child, representing reaching 287 million people living in poverty with effective social protection support.\\n4. A person drinking water, representing providing healthy water, sanitation, and/or hygiene to 59 million people.\\n5. A train, representing enabling access to sustainable transportation for 77 million people.\\n6. A person working on power lines, representing providing 17 gigawatts of renewable energy capacity.\\n7. A landscape of plants/trees, representing the commitment to devote 45 percent of annual financing to climate action by 2025.\\n\\nThese images supplement the statistics provided, visualizing the contributions and impact of the World Bank Group.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>images/page_5.png</td>\n",
       "      <td>**TRANSCRIPTION OF THE TEXT:**\\n\\n**MESSAGE FROM THE PRESIDENT**\\n\\n**DELIVERING ON OUR COMMITMENTS REQUIRES US TO DEVELOP NEW AND BETTER WAYS OF WORKING. IN FISCAL 2024, WE DID JUST THAT.**\\n**AJAY BANGA**\\n\\nIn fiscal 2024, the World Bank Group adopted a bold new vision of a world free of poverty on a livable planet. To achieve this, the Bank Group is enacting reforms to become a better partner to governments, the private sector, and, ultimately, the people we serve. Rarely in our 80-year history has our work been more urgent. We face declining progress in our fight against poverty, an existential climate crisis, mounting public debt, food insecurity, an unequal pandemic recovery, and the effects of geopolitical conflict.\\n\\nResponding to these intertwined challenges requires a faster, simpler, and more efficient World Bank Group. We are refocusing to confront these challenges not just through funding, but with knowledge. Our Knowledge Compact for Action, published in fiscal 2024, details how we will empower all our Bank Group clients, public and private, by making our wealth of development knowledge more accessible. And we have reorganized the World Bank’s global practices into five Vice Presidencies—People, Prosperity, Planet, Infrastructure, and Digital—for more flexible and faster engagements with clients. Each of these units reached important milestones in fiscal 2024.\\n\\nWe are supporting countries in delivering quality, affordable health services to 1.5 billion people by 2030 so our children and grandchildren will lead healthier, better lives. This is part of our larger global effort to provide a basic standard of care through every stage of a person’s life—infancy, childhood, adolescence, and adulthood. To help people withstand food-affected shocks and crises, we are strengthening social protection services to support half a billion people by the end of 2030—aiming for half of these beneficiaries to be women.\\n\\nWe are helping developing countries create jobs and employment, the surest enablers of prosperity. In the next 10 years, 1.2 billion young people across the Global South will become working-age adults. Yet, in the same period and the same countries, only 424 million jobs are expected to be created. The cost of hundreds of millions of young people with no hope for a decent job or future is unimaginable, and we are working urgently to create opportunity for all.\\n\\nIn response to climate change—arguably the greatest challenge of our generation—we’re channeling 45 percent of annual financing to climate action by 2025, deployed equally between mitigation and adaptation. Among other efforts, we intend to launch at least 15 country-led methane-reduction programs by fiscal 2026, and our Forest Carbon Partnership Facility has helped strengthen high-integrity carbon markets.\\n\\nRecognizing that digitalization is the transformational opportunity of our time, we are collaborating with governments in more than 100 developing countries to enable digital economies. Our digital lending portfolio totaled $5.6 billion in commitments as of June 2024; and our new Digital Vice Presidency unit will lead our efforts to establish the foundations of a digital economy. Key initiatives include building and enhancing digital and data infrastructure, ensuring cybersecurity and data privacy for institutions, businesses, and citizens, and advancing digital government services.\\n\\nDelivering on our commitments requires us to develop new and better ways of working. In fiscal 2024, we did just that. We are squeezing up our balance sheet and finding new opportunities to take more risk and boost our lending. Our new crisis preparedness and response tools, Global Challenge Programs, and Livable Planet Fund demonstrate how we are modernizing our approach to better drive impact and outcomes. Our new Scorecard radically changes how we track results.\\n\\nBut we cannot achieve development on our own. We need partners from both the public and private sectors to join our efforts. That's why we are working closely with other multilateral development banks to improve the lives of people in developing countries in tangible, measurable ways. Our deepening relationship with the private sector is evidenced by our Private Sector Investment Lab, which is working to address the barriers preventing private sector investment in emerging markets. The Lab’s core group of 15 Chief Executive Officers and Chairs meets regularly, and their advice has informed our work—most notably with the development of the World Bank Group Guarantee Platform.\\n\\nThe impact and innovations we delivered this year will allow us to move forward with a raised ambition and a great sense of urgency to improve people’s lives. I would like to recognize the remarkable efforts of our staff and Executive Directors, as well as the unwavering support of all our clients and partners. Together, we head into fiscal 2025 with a great sense of optimism—and determination to create better Bank for a better world.\\n\\n**AJAY BANGA**\\n**President of the World Bank Group and Chairman of the Board of Executive Directors**\\n\\n**DESCRIPTION OF THE IMAGE OR CHART**\\nThe image portrays two individuals interacting with a young child, who appears to be engaged with fresh produce, specifically tomatoes. The background suggests a natural or rural setting, with elements of vegetation visible. The scene reflects themes of agriculture, nurturing, and community interaction.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "# Convert the DataFrame to an HTML table and display top 5 rows \n",
    "display(HTML(df.head().to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**TRANSCRIPTION OF THE TEXT:**\n",
      "\n",
      "We also committed $35 million in grants to support emergency relief in Gaza. Working with the World Food Programme, the World Health Organization, and the UN Children’s Fund, the grants support the delivery of emergency food, water, and medical supplies. In the West Bank, we approved a $30 million grant for the continuation of education for children, $22 million to support municipal services, and $45 million to strengthen healthcare and hospital services.\n",
      "\n",
      "Enabling green and inclusive growth\n",
      "To help policymakers in the region advance their climate change and development goals, we published Country Climate and Development Reports for the West Bank and Gaza, Lebanon, and Tunisia. In Libya, the catastrophic flooding in September 2023 devastated eastern localities, particularly the city of Derna. The World Bank, together with the UN and the European Union, produced a Rapid Damage and Needs Assessment to inform recovery and reconstruction efforts.\n",
      "\n",
      "We signed a new Memorandum of Understanding (MoU) with the Islamic Development Bank to promote further collaboration between our institutions. The MoU focuses on joint knowledge and operational engagements around the energy, food, and water nexus, climate impact, empowering women and youth to engage with the private sector, and advancing the digital transition and regional integration. The MoU aims to achieve a co-financing volume of $6 billion through 2026, 45 percent of which has already been met.\n",
      "\n",
      "Expanding economic opportunities for women\n",
      "The World Bank has drawn on a variety of instruments to support Jordan’s commitment to increase female labor force participation, including through the recently approved Country Partnership Framework. Through operations, technical assistance (such as Mashreq Gender Facility: Women Entrepreneurs Finance Initiative and the Women, Business and the Law report), and policy dialogue, we have contributed to legal reforms in Jordan that removed job restrictions on women, prohibited gender-based discrimination in the workplace, and criminalized sexual harassment in the workplace. In fiscal 2024, we approved the first women-focused Bank project in the region: the Enhancing Women’s Economic Opportunities Program for Results aims to improve workplace conditions, increase financial inclusion and entrepreneurship, make public transport safer, and increase access to affordable, quality childcare services.\n",
      "\n",
      "Analyzing critical infrastructure needs\n",
      "We published an Interim Damage Assessment for Gaza in partnership with the UN and with financial support from the EU. This found that a preliminary estimate of the cost of damages to critical infrastructure from the conflict in Gaza between October 2023 and the end of January 2024 was around $18.5 billion—equivalent to 37 percent of the 2022 GDP of the West Bank and Gaza combined. When the situation allows, a full-fledged Rapid Damage and Needs Assessment will be conducted.\n",
      "\n",
      "**COUNTRY IMPACT**\n",
      "\n",
      "Egypt: The Bank-supported Takaful and Karama social protection program has reached 4.7 million vulnerable households, benefitting approximately 20 million individuals, 75 percent of them women.\n",
      "\n",
      "Lebanon: A roads project has rehabilitated over 500 km of roads in 25 districts across the country and generated 1.3 million labor days for Lebanese workers and Syrian refugees.\n",
      "\n",
      "Morocco: Our programs have benefited more than 400,000 people directly, and more than 33 million people indirectly, through more than 230 disaster risk reduction projects.\n",
      "\n",
      "**DESCRIPTION OF THE IMAGE OR CHART**\n",
      "\n",
      "The chart titled \"FIGURE 6: MIDDLE EAST AND NORTH AFRICA IBRD AND IDA LENDING BY SECTOR - FISCAL 2024 SHARE OF TOTAL OF $4.6 BILLION\" is a pie chart. It shows the distribution of lending by sector with the following proportions:\n",
      "- Public Administration: 24%\n",
      "- Social Protection: 13%\n",
      "- Water, Sanitation, and Waste Management: 8%\n",
      "- Transportation: 5%\n",
      "- Agriculture, Fishing, and Forestry: 8%\n",
      "- Education: 17%\n",
      "- Energy and Extractives: 3%\n",
      "- Financial Sector: 11%\n",
      "- Health: 13%\n",
      "- Industry, Trade, and Services: 2%\n",
      "- Information and Communications Technologies: 6%\n",
      "\n",
      "**TRANSCRIPTION OF THE TABLE**\n",
      "\n",
      "**TABLE 13: MIDDLE EAST AND NORTH AFRICA REGIONAL SNAPSHOT**\n",
      "\n",
      "| INDICATOR                                       | 2000     | 2012        | CURRENT DATA* |\n",
      "|-------------------------------------------------|----------|-------------|---------------|\n",
      "| Total population (millions)                     | 283.9    | 356.2       | 430.9         |\n",
      "| Population growth (annual %)                    | 2.0      | 1.8         | 1.5           |\n",
      "| GNI per capita (Atlas method, current US$)      | 1,595.5  | 4,600.4     | 3,968.1       |\n",
      "| GDP per capita growth (annual %)                | 4.0      | 1.7         | 1.2           |\n",
      "| Population living below $2.15 a day (millions)  | 97.8     | 82.8        | 19.1          |\n",
      "| Life expectancy at birth, females (years)       | 70.8     | 73.9        | 74.8          |\n",
      "| Life expectancy at birth, males (years)         | 66.5     | 69.9        | 69.9          |\n",
      "| Carbon dioxide emissions (megatons)             | 813.2    | 1,297.7     | 1,370.9       |\n",
      "| Extreme poverty (% of population below $2.15 a day, 2017 PPP) | 3.4 | 2.3   | 4.7           |\n",
      "| Debt service as a proportion of exports of goods, services, and primary income | 15.1 | 5.2 | 12.4 |\n",
      "| Ratio of female to male labor force participation rate (%) (modeled ILO estimate) | 24.5 | 26.2 | 23.2 |\n",
      "| Vulnerable employment, total (% of total employment) (modeled ILO estimate) | 35.4 | 31.7 | 31.4 |\n",
      "| Under-5 mortality rate per 1,000 live births    | 46.7     | 29.0        | 20.9          |\n",
      "| Primary completion rate (% of relevant age group) | 81.4   | 88.9        | 86.7          |\n",
      "| Individuals using the internet (% of population)| 0.9      | 26.0        | 73.4          |\n",
      "| Access to electricity (% of population)         | 91.4     | 94.7        | 96.9          |\n",
      "| Renewable energy consumption (% of total final energy consumption) | 3.0 | 2.6 | 2.9 |\n",
      "| People using at least basic drinking water services (% of population) | 86.5 | 90.6 | 93.7 |\n",
      "| People using at least basic sanitation services (% of population) | 79.4 | 86.2 | 90.4 |\n",
      "\n",
      "Note: ILO = International Labour Organization. PPP = purchasing power parity. \n",
      "\n",
      "a. The most current data available between 2018 and 2023; visit https://data.worldbank.org for data updates.\n",
      "\n",
      "For more information, visit www.worldbank.org/mena.\n",
      "\n",
      "---\n",
      "\n",
      "*THE WORLD BANK ANNUAL REPORT 2024*\n"
     ]
    }
   ],
   "source": [
    "# Filter and print rows where pageNumber is 21\n",
    "filtered_rows = df[df['PageNumber'] == 21]\n",
    "for text in filtered_rows.PageText:\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Embeddings: 100%|██████████| 49/49 [00:09<00:00,  4.95it/s]\n"
     ]
    }
   ],
   "source": [
    "# Add a column to flag pages with visual content\n",
    "df['Visual_Input_Processed'] = df['PageText'].apply(\n",
    "    lambda x: 'Y' if 'DESCRIPTION OF THE IMAGE OR CHART' in x or 'TRANSCRIPTION OF THE TABLE' in x else 'N'\n",
    ")\n",
    "\n",
    "\n",
    "# Function to get embeddings\n",
    "def get_embedding(text_input):\n",
    "    response = oai_client.embeddings.create(\n",
    "        input=text_input,\n",
    "        model=\"text-embedding-3-large\"\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "\n",
    "\n",
    "# Generate embeddings with a progress bar\n",
    "embeddings = []\n",
    "for text in tqdm(df['PageText'], desc='Generating Embeddings'):\n",
    "    embedding = get_embedding(text)\n",
    "    embeddings.append(embedding)\n",
    "\n",
    "# Add the embeddings to the DataFrame\n",
    "df['Embeddings'] = embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20    Y\n",
      "Name: Visual_Input_Processed, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Display the flag for page 21 \n",
    "filtered_rows = df[df['PageNumber'] == 21]\n",
    "print(filtered_rows.Visual_Input_Processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading embeddings to Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading to Pinecone: 100%|██████████| 49/49 [00:09<00:00,  5.10it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "index_name = \"my-test-index\"\n",
    "\n",
    "# Initialize a Pinecone client with your API key\n",
    "pc = Pinecone(api_key)\n",
    "\n",
    "# reload the index from Pinecone \n",
    "index = pc.Index(index_name)\n",
    "\n",
    "# Create a document ID prefix \n",
    "document_id = 'WB_Report'\n",
    "\n",
    "\n",
    "# Define the async function correctly\n",
    "def upsert_vector(identifier, embedding, metadata):\n",
    "    try:\n",
    "        index.upsert([\n",
    "            {\n",
    "                'id': identifier,\n",
    "                'values': embedding,\n",
    "                'metadata': metadata\n",
    "            }\n",
    "        ])\n",
    "    except Exception as e:\n",
    "        print(f\"Error upserting vector with ID {identifier}: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=df.shape[0], desc='Uploading to Pinecone'):\n",
    "    pageNumber = row['PageNumber']\n",
    "\n",
    "    # Create meta-data tags to be added to Pinecone \n",
    "    metadata = {\n",
    "        'pageId': f\"{document_id}-{pageNumber}\",\n",
    "        'pageNumber': pageNumber,\n",
    "        'text': row['PageText'],\n",
    "        'ImagePath': row['ImagePath'],\n",
    "        'GraphicIncluded': row['Visual_Input_Processed']\n",
    "    }\n",
    "\n",
    "    upsert_vector(metadata['pageId'], row['Embeddings'], metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing Semantic Search for Relevant Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Function to get response to a user's question \n",
    "def get_response_to_question(user_question, pc_index):\n",
    "    # Get embedding of the question to find the relevant page with the information \n",
    "    question_embedding = get_embedding(user_question)\n",
    "\n",
    "    # get response vector embeddings \n",
    "    response = pc_index.query(\n",
    "        vector=question_embedding,\n",
    "        top_k=2,\n",
    "        include_values=True,\n",
    "        include_metadata=True\n",
    "    )\n",
    "\n",
    "    # Collect the metadata from the matches\n",
    "    context_metadata = [match['metadata'] for match in response['matches']]\n",
    "\n",
    "    # Convert the list of metadata dictionaries to prompt a JSON string\n",
    "    context_json = json.dumps(context_metadata, indent=3)\n",
    "\n",
    "    prompt = f\"\"\"You are a helpful assistant. Use the following context and images to answer the question. In the answer, include the reference to the document, and page number you found the information on between <source></source> tags. If you don't find the information, you can say \"I couldn't find the information\"\n",
    "\n",
    "    question: {user_question}\n",
    "    \n",
    "    <SOURCES>\n",
    "    {context_json}\n",
    "    </SOURCES>\n",
    "    \"\"\"\n",
    "\n",
    "    # Call completions end point with the prompt \n",
    "    completion = oai_client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage allocated to social protections in Western and Central Africa is 8% as shown in the pie chart on page 13.\n",
      "\n",
      "<source>WB_Report-13</source>\n"
     ]
    }
   ],
   "source": [
    "question = \"What percentage was allocated to social protections in Western and Central Africa?\"\n",
    "answer = get_response_to_question(question, index)\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The increase in access to electricity in Western and Central Africa between 2000 and 2012 was 10%, from 34.1% in 2000 to 44.1% in 2012.\n",
      "\n",
      "<source>WB_Report-13, page 13</source>\n"
     ]
    }
   ],
   "source": [
    "question = \"What was the increase in access to electricity between 2000 and 2012 in Western and Central Africa?\"\n",
    "answer = get_response_to_question(question, index)\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Pages with Visual Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "\n",
    "\n",
    "def get_response_to_question_with_images(user_question, pc_index):\n",
    "    # Get embedding of the question to find the relevant page with the information \n",
    "    question_embedding = get_embedding(user_question)\n",
    "\n",
    "    # Get response vector embeddings \n",
    "    response = pc_index.query(\n",
    "        vector=question_embedding,\n",
    "        top_k=3,\n",
    "        include_values=True,\n",
    "        include_metadata=True\n",
    "    )\n",
    "\n",
    "    # Collect the metadata from the matches\n",
    "    context_metadata = [match['metadata'] for match in response['matches']]\n",
    "\n",
    "    # Build the message content\n",
    "    message_content = []\n",
    "\n",
    "    # Add the initial prompt\n",
    "    initial_prompt = f\"\"\"You are a helpful assistant. Use the text and images provided by the user to answer the question. You must include the reference to the page number or title of the section you the answer where you found the information. If you don't find the information, you can say \"I couldn't find the information\"\n",
    "\n",
    "    question: {user_question}\n",
    "    \"\"\"\n",
    "    \n",
    "    message_content.append({\"role\": \"system\", \"content\": initial_prompt})\n",
    "    \n",
    "    context_messages = []\n",
    "\n",
    "    # Process each metadata item to include text or images based on 'Visual_Input_Processed'\n",
    "    for metadata in context_metadata:\n",
    "        visual_flag = metadata.get('GraphicIncluded')\n",
    "        page_number = metadata.get('pageNumber')\n",
    "        page_text = metadata.get('text')\n",
    "        message =\"\"\n",
    "\n",
    "        if visual_flag =='Y':\n",
    "            # Include the image\n",
    "            print(f\"Adding page number {page_number} as an image to context\")\n",
    "            image_path = metadata.get('ImagePath', None)\n",
    "            try:\n",
    "                base64_image = encode_image(image_path)\n",
    "                image_type = 'jpeg'\n",
    "                # Prepare the messages for the API call\n",
    "                context_messages.append({\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/{image_type};base64,{base64_image}\"\n",
    "                    },\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error encoding image at {image_path}: {e}\")\n",
    "        else:\n",
    "            # Include the text\n",
    "            print(f\"Adding page number {page_number} as text to context\")\n",
    "            context_messages.append({\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": f\"Page {page_number} - {page_text}\",\n",
    "                })\n",
    "        \n",
    "                # Prepare the messages for the API call\n",
    "        messages =  {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": context_messages\n",
    "        }\n",
    "    \n",
    "    message_content.append(messages)\n",
    "\n",
    "    completion = oai_client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=message_content\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding page number 13.0 as an image to context\n",
      "Adding page number 12.0 as an image to context\n",
      "Adding page number 11.0 as an image to context\n",
      "The percentage allocated to social protections in Western and Central Africa is 8%. This information can be found in Figure 2 on page 22 of the document.\n"
     ]
    }
   ],
   "source": [
    "question = \"What percentage was allocated to social protections in Western and Central Africa?\"\n",
    "answer = get_response_to_question_with_images(question, index)\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding page number 32.0 as text to context\n",
      "Adding page number 30.0 as an image to context\n",
      "Adding page number 34.0 as an image to context\n",
      "In the image associated with digital improvements on page 32 of the document, there is a person seated at a desk using a laptop and holding a smartphone. The desk has various electronic devices and cables. The setting appears to be in a workspace with other individuals visible in the background, indicating a collaborative work environment centered around digital engagement.\n"
     ]
    }
   ],
   "source": [
    "question = \"Can you find the image associated with digital improvements and describe what you see in the images?\"\n",
    "answer = get_response_to_question_with_images(question, index)\n",
    "\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
